{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscie-89_Moore_Adrianna_HW10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5UuojJxtZcp"
   },
   "source": [
    "## Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvKPz4mrto92"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ody4XIJQyk2Z"
   },
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOFl--UdtdJS"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgrjPq2FtTJr"
   },
   "outputs": [],
   "source": [
    "URL = \"https://www.manythings.org/anki/fra-eng.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUIpjR0Wtsy5"
   },
   "outputs": [],
   "source": [
    "# Function to download and extract the dataset\n",
    "def download_and_extract(url):\n",
    "    os.makedirs('dataset', exist_ok = True)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the zip file\n",
    "        with ZipFile(io.BytesIO(response.content), 'r') as zip_ref:\n",
    "            # Specify the directory where you want to extract the files\n",
    "            zip_ref.extractall(\"/content/dataset/\")\n",
    "        print(\"Dataset downloaded and extracted successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the dataset. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZky9YSetvNq",
    "outputId": "07367ccc-9fe4-4772-a3d6-e64284f33d6d"
   },
   "outputs": [],
   "source": [
    "#call function\n",
    "download_and_extract(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRjkek5Xtxvw"
   },
   "outputs": [],
   "source": [
    "# Setting the variable 'data_dir' to the path of the dataset directory.\n",
    "data_dir = '/content/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYWFXyNlujoG"
   },
   "outputs": [],
   "source": [
    "text = (Path(data_dir).with_name(\"dataset\") / \"fra.txt\").read_text()  # Reading the content of 'fra.txt' from the 'dataset' directory into the variable 'text'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JcZqXjwwk-L"
   },
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1UpZA0zv73n"
   },
   "outputs": [],
   "source": [
    "# Removing specific characters ('¡', '¿') from the text.\n",
    "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
    "# Splitting the text into lines and each line into pairs using tab as a delimiter.\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1qUq9wYv8vX",
    "outputId": "f9848e8a-1423-4e4d-be2d-dbeb0b5a41d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.',\n",
       " 'Va !',\n",
       " 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0]  # Accessing the first element (pair) of the 'pairs' list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx4M9U6gwm3b"
   },
   "source": [
    "### Pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3VlpJxCvuyu"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)  # extra code – ensures reproducibility on CPU\n",
    "np.random.shuffle(pairs)\n",
    "sentences_en, sentences_fra, _ = zip(*pairs)  # separates the pairs into 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFbXjY9fv11j",
    "outputId": "37865dd0-15d0-4fc2-b450-acfa4e0f8b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just wanted to make you happy. => Je voulais simplement te rendre heureuse.\n",
      "We can't be the only two people who're late. => Nous ne pouvons être les deux seules personnes à être en retard.\n",
      "I know that Tom has been sick. => Je sais que Tom était malade.\n"
     ]
    }
   ],
   "source": [
    "# Looping through the first three elements, printing English sentences and their corresponding French translations.\n",
    "for i in range(3):\n",
    "    print(sentences_en[i], \"=>\", sentences_fra[i])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLTLEjkYwtSC"
   },
   "source": [
    "### VOCAB size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiUXAxjzws-y"
   },
   "outputs": [],
   "source": [
    "vocab_size = 2000  # Setting the vocabulary size to 2000.\n",
    "\n",
    "max_length = 70  # Defining the maximum length of sentences as 70 characters/words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqwgGC2DwSdL"
   },
   "outputs": [],
   "source": [
    "# Creating a TextVectorization layer for English text with defined vocab size and max length.\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(vocab_size, output_sequence_length=max_length)  \n",
    "\n",
    "# Creating a TextVectorization layer for French text with the same parameters.\n",
    "text_vec_layer_fra = tf.keras.layers.TextVectorization(vocab_size, output_sequence_length=max_length)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diyNlk0Gw8T4"
   },
   "outputs": [],
   "source": [
    "# Adapting the English TextVectorization layer to the English sentences dataset.\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "\n",
    "# Adapting the French TextVectorization layer to the French sentences dataset, adding start and end tokens to each sentence.\n",
    "text_vec_layer_fra.adapt([f\"startofseq {s} endofseq\" for s in sentences_fra])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7zjrAMkxLab"
   },
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CZMNIE8w9cY",
    "outputId": "336cf00a-fa0a-4f14-cc31-1d0a899f7a8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'i', 'you', 'to', 'the', 'a', 'tom', 'is', 'that']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the first 10 words from the vocabulary of the English TextVectorization layer.\n",
    "text_vec_layer_en.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnCgqwY1xQEz",
    "outputId": "fce3148e-7d5c-46ad-ee45-dd8a802adcfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'je', 'de', 'pas', 'que', 'ne', 'le']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving the first 10 words from the vocabulary of the French TextVectorization layer.\n",
    "text_vec_layer_fra.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZZMV3FqxXGl"
   },
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzDtvq2J0utl"
   },
   "outputs": [],
   "source": [
    "# Setting the variable 'total_pairs' to the total number of sentence pairs in the dataset.\n",
    "total_pairs = 227815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIjeSovQ0zBj"
   },
   "outputs": [],
   "source": [
    "# Setting 'total_samples' equal to 'total_pairs'.\n",
    "total_samples = total_pairs\n",
    "\n",
    "# Calculating the size of the training set as 50% of total samples.\n",
    "train_size = int(0.5 * total_samples)\n",
    "\n",
    "# Calculating the size of the validation set as 45% of total samples.\n",
    "valid_size = int(0.45 * total_samples)\n",
    "\n",
    "# Calculating the size of the test set as 15% of total samples.\n",
    "test_size = int(0.15 * total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBYFyB2z0sS7"
   },
   "outputs": [],
   "source": [
    "# Define the training dataset for English sentences.\n",
    "X_train = tf.constant(sentences_en[:train_size])\n",
    "\n",
    "# Define the validation dataset for English sentences.\n",
    "X_valid = tf.constant(sentences_en[train_size:train_size + valid_size])\n",
    "\n",
    "# Define the test dataset for English sentences.\n",
    "X_test = tf.constant(sentences_en[train_size + valid_size:])\n",
    "\n",
    "# Prepend \"startofseq\" to each French sentence for the training dataset.\n",
    "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_fra[:train_size]])\n",
    "\n",
    "# Prepend \"startofseq\" to each French sentence for the validation dataset.\n",
    "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_fra[train_size:train_size + valid_size]])\n",
    "\n",
    "# Prepend \"startofseq\" to each French sentence for the test dataset.\n",
    "X_test_dec = tf.constant([f\"startofseq {s}\" for s in sentences_fra[train_size + valid_size:]])\n",
    "\n",
    "# Append \"endofseq\" to each French sentence and vectorize for the training dataset.\n",
    "Y_train = text_vec_layer_fra([f\"{s} endofseq\" for s in sentences_fra[:train_size]])\n",
    "\n",
    "# Append \"endofseq\" to each French sentence and vectorize for the validation dataset.\n",
    "Y_valid = text_vec_layer_fra([f\"{s} endofseq\" for s in sentences_fra[train_size:train_size + valid_size]])\n",
    "\n",
    "# Append \"endofseq\" to each French sentence and vectorize for the test dataset.\n",
    "Y_test = text_vec_layer_fra([f\"{s} endofseq\" for s in sentences_fra[train_size + valid_size:]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up6dw9bvyMWC"
   },
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpmS0qW3yPC6",
    "outputId": "21f609d9-5362-4394-c3ed-d6633e4d5314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 113907\n",
      "Number of samples in validation set: 102516\n",
      "Number of samples in test set: 11392\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to verify data split\n",
    "# Printing the number of samples in the training set.\n",
    "print(\"Number of samples in training set:\", len(X_train))\n",
    "\n",
    "# Printing the number of samples in the validation set.\n",
    "print(\"Number of samples in validation set:\", len(X_valid))\n",
    "\n",
    "# Printing the number of samples in the test set.\n",
    "print(\"Number of samples in test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRbo6eDvyTc5",
    "outputId": "7029e17f-057b-41e0-ff36-f34956fcc3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 227815\n"
     ]
    }
   ],
   "source": [
    "# Verify that the total number of samples matches the original dataset\n",
    "total_samples = len(X_train) + len(X_valid) + len(X_test)\n",
    "print(\"Total number of samples:\", total_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmAMzX_nzOSq"
   },
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-u3eagUzcy4"
   },
   "outputs": [],
   "source": [
    "# Setting the embedding size to 128 for the neural network model.\n",
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymGvkmcwzQ7G"
   },
   "outputs": [],
   "source": [
    "# Setting a fixed random seed to ensure reproducibility of results.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Creating an input layer for the encoder in the model, expecting string data.\n",
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "\n",
    "# Creating an input layer for the decoder in the model, also expecting string data.\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQeOzWAwzbNS"
   },
   "outputs": [],
   "source": [
    "# Transforming the encoder inputs into a sequence of integers using the English TextVectorization layer.\n",
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "\n",
    "# Transforming the decoder inputs into a sequence of integers using the French TextVectorization layer.\n",
    "decoder_input_ids = text_vec_layer_fra(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHcU6cIfzSl7"
   },
   "outputs": [],
   "source": [
    "# Creating an embedding layer for the encoder with specified vocabulary size and embedding size, enabling zero masking.\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n",
    "\n",
    "# Creating a similar embedding layer for the decoder, also with zero masking.\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Fk5cAQAzjgt"
   },
   "outputs": [],
   "source": [
    "# Applying the encoder embedding layer to the encoder input IDs to obtain the corresponding embeddings.\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "\n",
    "# Applying the decoder embedding layer to the decoder input IDs to obtain the corresponding embeddings.\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4LdANMcy3nl"
   },
   "source": [
    "## Attention Mechanism Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbJb1IOqynmg"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True, return_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jb-kxWu3y_AV"
   },
   "outputs": [],
   "source": [
    "# extra code – this part of the model is exactly the same as earlier\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
    "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e24WbjCmzvUo"
   },
   "outputs": [],
   "source": [
    "# Initializing a LSTM layer for the decoder with 512 units, set to return sequences.\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "\n",
    "# Applying the decoder LSTM to the decoder embeddings, using the encoder's state as the initial state.\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv92iHy7z1KG"
   },
   "source": [
    "#### Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38sn_YlMzxbH"
   },
   "outputs": [],
   "source": [
    "# Creating an Attention layer to focus on different parts of the encoder output during decoding.\n",
    "attention_layer = tf.keras.layers.Attention()\n",
    "\n",
    "# Applying the attention layer to the decoder outputs and encoder outputs.\n",
    "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Initializing a Dense layer with softmax activation to output probability distribution over the vocabulary.\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "\n",
    "# Applying the output layer to the attention outputs to get the final probability distribution for each word.\n",
    "Y_proba = output_layer(attention_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xl-kReKzz4H_"
   },
   "outputs": [],
   "source": [
    "# Constructing the model by specifying its inputs (encoder and decoder inputs) and outputs (probabilities).\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "\n",
    "# Compiling the model with sparse categorical crossentropy loss, Nadam optimizer, and tracking accuracy as a metric.\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AxzzLQmnEt8"
   },
   "outputs": [],
   "source": [
    "# Importing the EarlyStopping callback from TensorFlow's Keras API.\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Setting up an EarlyStopping callback to monitor validation loss, with patience of 3 epochs and restoration of the best model weights.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ffy3z8Alz7Td",
    "outputId": "17080890-4b0f-4342-e264-ad03fdf365ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "112/112 [==============================] - 47s 418ms/step - loss: 1.5446 - accuracy: 0.6359 - val_loss: 1.7107 - val_accuracy: 0.6092\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 51s 461ms/step - loss: 1.4727 - accuracy: 0.6493 - val_loss: 1.6796 - val_accuracy: 0.6147\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 52s 465ms/step - loss: 1.4113 - accuracy: 0.6611 - val_loss: 1.6439 - val_accuracy: 0.6214\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 52s 461ms/step - loss: 1.3554 - accuracy: 0.6723 - val_loss: 1.6074 - val_accuracy: 0.6302\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 52s 463ms/step - loss: 1.3057 - accuracy: 0.6821 - val_loss: 1.5890 - val_accuracy: 0.6348\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 46s 413ms/step - loss: 1.2569 - accuracy: 0.6920 - val_loss: 1.5770 - val_accuracy: 0.6376\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 52s 463ms/step - loss: 1.2161 - accuracy: 0.7007 - val_loss: 1.5909 - val_accuracy: 0.6366\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 46s 413ms/step - loss: 1.1757 - accuracy: 0.7093 - val_loss: 1.5640 - val_accuracy: 0.6411\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 52s 463ms/step - loss: 1.1391 - accuracy: 0.7170 - val_loss: 1.5583 - val_accuracy: 0.6442\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 52s 464ms/step - loss: 1.1018 - accuracy: 0.7247 - val_loss: 1.5502 - val_accuracy: 0.6466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x78d1da3aedd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((X_train, X_train_dec), Y_train, epochs=20, batch_size=1024,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfmwT0dCBHb0"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLhjlg0Cz95B"
   },
   "outputs": [],
   "source": [
    "# Defining a function 'translate' to convert an English sentence to French using the trained model.\n",
    "def translate(sentence_en):\n",
    "    translation = \"\"\n",
    "    # Looping through each word index up to the maximum length.\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])  # Preparing the encoder input.\n",
    "        X_dec = np.array([\"startofseq \" + translation])  # Preparing the decoder input with the current translation.\n",
    "\n",
    "        # Predicting the next word's probability distribution using the model.\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]\n",
    "\n",
    "        # Selecting the word with the highest probability.\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_fra.get_vocabulary()[predicted_word_id]\n",
    "\n",
    "        # Breaking the loop if the end-of-sequence token is predicted.\n",
    "        if predicted_word == \"endofseq\":\n",
    "            break\n",
    "\n",
    "        # Adding the predicted word to the translation.\n",
    "        translation += \" \" + predicted_word\n",
    "\n",
    "    # Returning the final translation, stripped of leading/trailing whitespace.\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLiK-z6xCJp9",
    "outputId": "c233f731-4e0f-49c4-918f-093b693d5b05"
   },
   "outputs": [],
   "source": [
    "# Preparing lists to store test sentences and their translations for evaluation.\n",
    "attention_model_test__en = []\n",
    "attention_model_test_fra = []\n",
    "attention_model_test_results_fra = []\n",
    "\n",
    "# Iterating over 10 random samples from the test dataset.\n",
    "for i in range(10):\n",
    "    random_index = np.random.randint(len(X_test))  # Selecting a random index from the test dataset.\n",
    "    sentence_en = X_test[random_index]  # Extracting an English sentence using the random index.\n",
    "    y_true = X_test_dec[random_index]  # Extracting the corresponding true French translation.\n",
    "\n",
    "    # Generating the predicted French translation using the translate function.\n",
    "    predicted_translation = translate(sentence_en.numpy())\n",
    "\n",
    "    # Appending the English sentence, predicted translation, and actual translation to their respective lists.\n",
    "    attention_model_test__en.append(sentence_en.numpy())\n",
    "    attention_model_test_results_fra.append(predicted_translation)\n",
    "    attention_model_test_fra.append(str(y_true.numpy().decode('utf-8')).split('startofseq ')[1])\n",
    "\n",
    "    # Printing the input English sentence, predicted French translation, and actual French translation.\n",
    "    print(\"Input (English):\", str(sentence_en.numpy()))\n",
    "    print(\"Predicted Translation (French):\", predicted_translation)\n",
    "    print(\"Actual Translation (French):\", y_true.numpy().decode('utf-8'))\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZQm3xsvHASL"
   },
   "source": [
    "### Evaluation (BLUE score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzLpcjlsF8jX",
    "outputId": "f73d673a-cbdb-4c75-b92d-97cd66ce9648"
   },
   "outputs": [],
   "source": [
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rXV44JQHK7I"
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "17cb74e7ccde4176b37c70db7f2827ef",
      "a9daccda74b54758875bafbf11212c81",
      "d8fb0e935f09496bac25aa3fddf16be4",
      "c25c76584bd740008e6dee60a3a52821",
      "2644859a14274703a9ef7a4ca999d3bc",
      "9a7a1d53e84947c7aa059f1e9eaa7747",
      "4fecd2e82e6b418e9e6e3ea5ff9617e2",
      "e3a0efe8426c4945a157c4f39b46cdeb",
      "a142794168b9416c9aaa80fb49f668b9",
      "da8f8fe4ef4b4bbb87acbcb94ae21f03",
      "640bb6bd59fb402cb87bc910bdfea9be",
      "d917fcf597d1461d8333e8637f4fc6c5",
      "866363d3aafe484b90becd99bf9176e1",
      "752bb9388daf4dcc8a335fd1bf6d8d77",
      "9cf5e2fa5a8c440eb4ef7aa2540280d7",
      "fa1de26e47644f5e99f4709e8dd9fe1b",
      "dcbaa7ce6a094e11b74cc4d673b3e786",
      "40ee584d517d4c2a8ef822fe7d7ac6f0",
      "a1e117055642430fb7fffc585be99960",
      "7f1bdc243687476baf0d58ec5e111a99",
      "b940754320304c1b905c80701a536612",
      "b3cd22d8466f401bbf44c15682e84822"
     ]
    },
    "id": "onRxEf9iHDyg",
    "outputId": "17b50c7c-f58c-48fe-866a-23fdf77a018c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cb74e7ccde4176b37c70db7f2827ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d917fcf597d1461d8333e8637f4fc6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the 'google_bleu' metric for evaluation from the 'evaluate' library.\n",
    "google_bleu_metric = evaluate.load(\"google_bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CAEmfjMHJre"
   },
   "outputs": [],
   "source": [
    "attention_model_BLUE = google_bleu_metric.compute(\n",
    "    predictions=attention_model_test_fra,\n",
    "    references=attention_model_test_results_fra,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imqWLbFoHgBT",
    "outputId": "a3544bba-0f50-45d3-ec54-a78ef12390ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION MODEL ROUGE RESULTS:\n",
      "{'google_bleu': 0.03205128205128205}\n"
     ]
    }
   ],
   "source": [
    "print('ATTENTION MODEL ROUGE RESULTS:')\n",
    "print(attention_model_BLUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vF946h7JJvl"
   },
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXUhq9XMJWRa"
   },
   "outputs": [],
   "source": [
    "# text = (Path(data_dir).with_name(\"dataset\") / \"fra.txt\").read_text()\n",
    "text = pathlib.Path(data_dir).parent / \"dataset\" / \"fra.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj_7FjkQJWRb"
   },
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tk-bL9RLJWRb"
   },
   "outputs": [],
   "source": [
    "# Open a text file for reading and assign its contents to the variable 'f'.\n",
    "with open(text) as f:\n",
    "    # Read the entire file, split it into lines, and remove the last line (which is often empty).\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "# Initialize an empty list to store pairs of text.\n",
    "text_pairs = []\n",
    "\n",
    "# Iterate through each line in the 'lines' list.\n",
    "for line in lines:\n",
    "    # Split each line by tabs and unpack the first two elements into 'eng' and 'fra', ignoring the rest.\n",
    "    eng, fra, _ = line.split(\"\\t\")\n",
    "\n",
    "    # Add start and end tokens to the French text for sequence demarcation.\n",
    "    fra = \"[start] \" + fra + \" [end]\"\n",
    "\n",
    "    # Append the pair (English, French) to the 'text_pairs' list.\n",
    "    text_pairs.append((eng, fra))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTJoWbKrJWRb",
    "outputId": "83cffd9a-6145-41f3-ffbb-00167b12d4b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"That's not a sentence you hear every day.\", \"[start] Ce n'est pas une phrase qu'on entend tous les jours. [end]\")\n",
      "('She scolded him for being late.', '[start] Elle le réprimanda pour son retard. [end]')\n",
      "(\"You're overworked.\", '[start] Vous êtes surmenés. [end]')\n",
      "(\"Don't touch my bike.\", '[start] Pas touche à mon vélo ! [end]')\n",
      "('I have a surprise for you, sweetheart.', \"[start] J'ai une surprise pour toi, mon chéri. [end]\")\n"
     ]
    }
   ],
   "source": [
    "# Loop five times to randomly select and print five pairs from 'text_pairs'.\n",
    "for _ in range(5):\n",
    "    # Randomly choose and print one pair from the 'text_pairs' list.\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nymwW0-fJWRf"
   },
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AUewnaPKkLJ",
    "outputId": "f18442ca-a2ef-47c6-81a2-452f0697576c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227815"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and return the total number of (English, French) pairs in the 'text_pairs' list.\n",
    "len(text_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lC9zPgqeKnvm"
   },
   "outputs": [],
   "source": [
    "# Calculate the total number of text pairs and store it in 'total_samples'.\n",
    "total_samples = len(text_pairs)\n",
    "\n",
    "# Calculate and store the size of the training dataset as 50% of the total samples.\n",
    "train_size = int(0.5 * total_samples)\n",
    "\n",
    "# Calculate and store the size of the validation dataset as 45% of the total samples.\n",
    "valid_size = int(0.45 * total_samples)\n",
    "\n",
    "# Calculate and store the size of the test dataset as 15% of the total samples.\n",
    "test_size = int(0.15 * total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18LLajGxK3z9"
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle the order of elements in the 'text_pairs' list.\n",
    "random.shuffle(text_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9Q0eLa-KfJF",
    "outputId": "48429c82-43c3-4a81-f0eb-cd56ed358974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227815 total pairs\n",
      "113907 training pairs\n",
      "102516 validation pairs\n",
      "11392 test pairs\n"
     ]
    }
   ],
   "source": [
    "# Split the shuffled 'text_pairs' into training, validation, and test sets based on their respective sizes.\n",
    "train_pairs = text_pairs[:train_size]\n",
    "valid_pairs = text_pairs[train_size:train_size + valid_size]\n",
    "test_pairs = text_pairs[train_size + valid_size:]\n",
    "\n",
    "# Print the total number of pairs in the dataset.\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "\n",
    "# Print the number of pairs in the training set.\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "\n",
    "# Print the number of pairs in the validation set.\n",
    "print(f\"{len(valid_pairs)} validation pairs\")\n",
    "\n",
    "# Print the number of pairs in the test set.\n",
    "print(f\"{len(test_pairs)} test pairs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iygG4RPkJWRd"
   },
   "source": [
    "### Vectorizing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGWqxZqfLEOd"
   },
   "outputs": [],
   "source": [
    "# Combine standard punctuation characters with the '¿' character to create a string of characters to be removed.\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "\n",
    "# Remove the '[' character from the 'strip_chars' string.\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "\n",
    "# Remove the ']' character from the 'strip_chars' string.\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wn6RUTKAJWRd"
   },
   "outputs": [],
   "source": [
    "# Initial setting of vocabulary size and maximum sentence length.\n",
    "vocab_size = 2000\n",
    "max_length = 70\n",
    "\n",
    "# Note explaining the initial settings: a vocabulary of 2000 words and sentence length up to 70 words.\n",
    "\n",
    "# Update to a larger vocabulary size and longer sequence length.\n",
    "vocab_size = 2500\n",
    "sequence_length = 80\n",
    "\n",
    "# Set the batch size for training to 64.\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5QFyc0zLYLF"
   },
   "outputs": [],
   "source": [
    "# Define a function for custom standardization of input strings.\n",
    "def custom_standardization(input_string):\n",
    "    # Convert all characters in the input string to lowercase.\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "\n",
    "    # Return the string after removing specified characters using regular expression.\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "# Create an English text vectorization layer.\n",
    "eng_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,                # Set the maximum vocabulary size.\n",
    "    output_mode=\"int\",                    # Specify output mode as integer (for token indices).\n",
    "    output_sequence_length=sequence_length # Set the length of the output sequences.\n",
    ")\n",
    "\n",
    "# Create a French text vectorization layer.\n",
    "fra_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,                       # Set the maximum vocabulary size.\n",
    "    output_mode=\"int\",                           # Specify output mode as integer.\n",
    "    output_sequence_length=sequence_length + 1,  # Set the length of the output sequences, one more than English.\n",
    "    standardize=custom_standardization,          # Use the custom standardization function.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41lxlJNvJWRe"
   },
   "outputs": [],
   "source": [
    "# Extract English texts from the training pairs and store them in a list.\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "\n",
    "# Extract French texts from the training pairs and store them in a list.\n",
    "train_fra_texts = [pair[1] for pair in train_pairs]\n",
    "\n",
    "# Adapt the English text vectorization layer to the training English texts.\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "\n",
    "# Adapt the French text vectorization layer to the training French texts.\n",
    "fra_vectorization.adapt(train_fra_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4P6lfkPJWRe"
   },
   "outputs": [],
   "source": [
    "# Define a function to format the dataset for the encoder and decoder inputs.\n",
    "def format_dataset(eng, spa):\n",
    "    # Vectorize the English text.\n",
    "    eng = eng_vectorization(eng)\n",
    "\n",
    "    # Vectorize the French text.\n",
    "    fra = fra_vectorization(spa)\n",
    "\n",
    "    # Return a dictionary of encoder and decoder inputs, along with the target (decoder output).\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": eng,\n",
    "            \"decoder_inputs\": fra[:, :-1],  # All but the last token for decoder input.\n",
    "        },\n",
    "        fra[:, 1:],  # All but the first token for the target (decoder output).\n",
    "    )\n",
    "\n",
    "# Define a function to create a TensorFlow dataset from text pairs.\n",
    "def make_dataset(pairs):\n",
    "    # Unzip the pairs into English and French texts and convert them to lists.\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    fra_texts = list(spa_texts)\n",
    "\n",
    "    # Create a TensorFlow dataset from the English and French texts.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fra_texts))\n",
    "\n",
    "    # Batch the dataset with the specified batch size.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Apply the 'format_dataset' function to each batch.\n",
    "    dataset = dataset.map(format_dataset)\n",
    "\n",
    "    # Shuffle, prefetch, and cache the dataset for efficient loading.\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_z3uVZzMP9E"
   },
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset for training using the 'train_pairs'.\n",
    "train_ds = make_dataset(train_pairs)\n",
    "\n",
    "# Create a TensorFlow dataset for validation using the 'valid_pairs'.\n",
    "val_ds = make_dataset(valid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfQKScy2MaJf",
    "outputId": "5866b14c-9b75-4f81-8f4e-da2576fc50d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 80)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 80)\n",
      "targets.shape: (64, 80)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the first batch of the training dataset to inspect input and target shapes.\n",
    "for inputs, targets in train_ds.take(1):\n",
    "    # Print the shape of the encoder inputs.\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "\n",
    "    # Print the shape of the decoder inputs.\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "\n",
    "    # Print the shape of the targets (decoder outputs).\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnQQ-_B_JWRe"
   },
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qu1hXnGxMjqC"
   },
   "outputs": [],
   "source": [
    "# Define a custom Transformer Encoder layer.\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Embedding dimensions, dense layer dimensions, and number of attention heads.\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Multi-head attention mechanism.\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "\n",
    "        # Feed-forward neural network for processing attention output.\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(dense_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "\n",
    "        # Layer normalization to stabilize the learning process.\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "        # Enable support for masking (ignoring certain values, like padding).\n",
    "        self.supports_masking = True\n",
    "\n",
    "    # Process input data.\n",
    "    def call(self, inputs, mask=None):\n",
    "        attention_output = self.attention(query=inputs, value=inputs, key=inputs)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    # Configuration for saving and loading the model.\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "# Define a custom layer for adding positional embeddings.\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Parameters for embeddings and sequence length.\n",
    "        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    # Process input tokens.\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    # Compute a mask for the inputs.\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    # Configuration for saving and loading the model.\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config\n",
    "# Define a custom Transformer Decoder layer.\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Embedding dimensions, latent dimensions, and number of attention heads.\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Two sets of multi-head attention mechanisms.\n",
    "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "\n",
    "        # Feed-forward neural network for processing attention output.\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(latent_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "        ])\n",
    "\n",
    "        # Layer normalization for each sublayer.\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "        # Custom addition layer to help with masking.\n",
    "        self.add = layers.Add()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    # Process input data, including encoder outputs.\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        attention_output_1 = self.attention_1(query=inputs, value=inputs, key=inputs, use_causal_mask=True)\n",
    "        out_1 = self.layernorm_1(self.add([inputs, attention_output_1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SShQ2E5Mj2K"
   },
   "outputs": [],
   "source": [
    "# Set the dimensionality of the embeddings to 256.\n",
    "embed_dim = 256\n",
    "\n",
    "# Set the dimensionality of the latent space to 2048.\n",
    "latent_dim = 2048\n",
    "\n",
    "# Set the number of attention heads to 8.\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIknQvO9Murt"
   },
   "outputs": [],
   "source": [
    "# Define the input layer for the encoder with variable sequence length.\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "\n",
    "# Apply positional embedding to the encoder inputs.\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "\n",
    "# Pass the embedded inputs through the Transformer encoder layer.\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "\n",
    "# Create the encoder model.\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "# Define the input layers for the decoder: one for the input sequences and one for the encoded sequences.\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "\n",
    "# Apply positional embedding to the decoder inputs.\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "\n",
    "# Pass the embedded inputs and encoder outputs through the Transformer decoder layer.\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "\n",
    "# Add a dropout layer for regularization.\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Final dense layer with softmax activation for outputting probability distribution over the vocabulary.\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "# Create the decoder model.\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "# Combine the encoder and decoder into a final Transformer model.\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "# Define the complete Transformer model with encoder and decoder inputs and outputs.\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a0MvzFNM0UL"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jY0v31HeMxPH",
    "outputId": "23d87b17-e3f3-4b29-aa3b-086c0105be67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1780/1780 [==============================] - 342s 186ms/step - loss: 1.2820 - accuracy: 0.7059 - val_loss: 1.1947 - val_accuracy: 0.7180\n",
      "Epoch 2/10\n",
      "1780/1780 [==============================] - 325s 182ms/step - loss: 1.1923 - accuracy: 0.7196 - val_loss: 1.1098 - val_accuracy: 0.7316\n",
      "Epoch 3/10\n",
      "1780/1780 [==============================] - 325s 182ms/step - loss: 1.0785 - accuracy: 0.7387 - val_loss: 1.0714 - val_accuracy: 0.7396\n",
      "Epoch 4/10\n",
      "1780/1780 [==============================] - 324s 182ms/step - loss: 0.9992 - accuracy: 0.7530 - val_loss: 1.0497 - val_accuracy: 0.7445\n",
      "Epoch 5/10\n",
      "1780/1780 [==============================] - 325s 182ms/step - loss: 0.9391 - accuracy: 0.7640 - val_loss: 1.0470 - val_accuracy: 0.7467\n",
      "Epoch 6/10\n",
      "1780/1780 [==============================] - 325s 182ms/step - loss: 0.8874 - accuracy: 0.7732 - val_loss: 1.0418 - val_accuracy: 0.7513\n",
      "Epoch 7/10\n",
      "1780/1780 [==============================] - 324s 182ms/step - loss: 0.8435 - accuracy: 0.7824 - val_loss: 1.0341 - val_accuracy: 0.7549\n",
      "Epoch 8/10\n",
      "1780/1780 [==============================] - 379s 213ms/step - loss: 0.8048 - accuracy: 0.7901 - val_loss: 1.0360 - val_accuracy: 0.7566\n",
      "Epoch 9/10\n",
      "1780/1780 [==============================] - 324s 182ms/step - loss: 0.7727 - accuracy: 0.7963 - val_loss: 1.0385 - val_accuracy: 0.7577\n",
      "Epoch 10/10\n",
      "1780/1780 [==============================] - 379s 213ms/step - loss: 0.7405 - accuracy: 0.8029 - val_loss: 1.0444 - val_accuracy: 0.7564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x78d1e4541ff0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10  \n",
    "\n",
    "# transformer.summary()\n",
    "transformer.compile(\n",
    "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, batch_size=1024)# Set the number of epochs for training the model.\n",
    "epochs = 10  \n",
    "\n",
    "# Compile the Transformer model.\n",
    "transformer.compile(\n",
    "    \"adam\",  # Use the Adam optimizer.\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Set the loss function to sparse categorical crossentropy.\n",
    "    metrics=[\"accuracy\"]  # Track accuracy during training.\n",
    ")\n",
    "\n",
    "# Train the Transformer model on the training dataset.\n",
    "transformer.fit(\n",
    "    train_ds,        # Training dataset.\n",
    "    epochs=epochs,   # Number of epochs to train for.\n",
    "    validation_data=val_ds,  # Validation dataset to evaluate the model.\n",
    "    batch_size=1024  # Batch size for training (note: typically defined earlier in the data pipeline, not here).\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NksxAlWIgpf0"
   },
   "source": [
    "### Tesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXibLA9Hgs8d"
   },
   "outputs": [],
   "source": [
    "# Retrieve the vocabulary from the French (Spanish in this context) vectorization layer.\n",
    "spa_vocab = fra_vectorization.get_vocabulary()\n",
    "\n",
    "# Create a lookup dictionary mapping indices to words in the French vocabulary.\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "\n",
    "# Set the maximum length for the decoded sentences.\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "# Define a function to decode an input sentence into its translated form.\n",
    "def decode_sequence(input_sentence):\n",
    "    # Vectorize the input English sentence.\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "\n",
    "    # Initialize the decoded sentence with the start token.\n",
    "    decoded_sentence = \"[start]\"\n",
    "\n",
    "    # Iterate up to the maximum decoded sentence length.\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        # Prepare the target (French) sentence for the Transformer model, excluding the last token for each iteration.\n",
    "        tokenized_target_sentence = fra_vectorization([decoded_sentence])[:, :-1]\n",
    "\n",
    "        # Generate predictions using the Transformer model.\n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        # Select the token with the highest probability at the current timestep.\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "\n",
    "        # Append the sampled token to the decoded sentence.\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Break the loop if the end token is reached.\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "\n",
    "    # Return the decoded sentence.\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg8EbW-D-u7q"
   },
   "outputs": [],
   "source": [
    "# Extract English texts from the test pairs and store them in a list.\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "\n",
    "# Extract French texts from the test pairs and store them in a list.\n",
    "test_fra_texts = [pair[1] for pair in test_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfGnjVz3-ZZL",
    "outputId": "b041fc28-aa28-449f-a94a-9747179f1857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (English): Don't let go. Hold on tight.\n",
      "Predicted Translation (French): [start] ne laissez pas [UNK] [UNK] [end]\n",
      "Actual Translation (French): [start] Ne lâche pas ! Tiens bon ! [end]\n",
      "----------\n",
      "Input (English): If you do that, you'll be making a fool of yourself.\n",
      "Predicted Translation (French): [start] si vous le faites vous serez [UNK] un [UNK] de vous [end]\n",
      "Actual Translation (French): [start] Tu vas te ridiculiser si tu fais ça. [end]\n",
      "----------\n",
      "Input (English): Give me half of it.\n",
      "Predicted Translation (French): [start] donnezmoi à moitié de ça [end]\n",
      "Actual Translation (French): [start] Donne-moi la moitié. [end]\n",
      "----------\n",
      "Input (English): If you could come, I'd be really happy.\n",
      "Predicted Translation (French): [start] si vous pourriez venir je serais vraiment heureux [end]\n",
      "Actual Translation (French): [start] Si vous pouviez venir, je serais vraiment heureuse. [end]\n",
      "----------\n",
      "Input (English): The answer isn't an easy one.\n",
      "Predicted Translation (French): [start] la réponse est un facile [end]\n",
      "Actual Translation (French): [start] La réponse n’est pas facile. [end]\n",
      "----------\n",
      "Input (English): Do you have a temperature?\n",
      "Predicted Translation (French): [start] astu de la [UNK] [end]\n",
      "Actual Translation (French): [start] As-tu de la température ? [end]\n",
      "----------\n",
      "Input (English): We took refuge in a cave and waited for the storm to pass.\n",
      "Predicted Translation (French): [start] nous avons pris une [UNK] dans une [UNK] à la tempête pour [UNK] [end]\n",
      "Actual Translation (French): [start] Nous nous réfugiâmes dans une grotte et attendîmes que la tempête passe. [end]\n",
      "----------\n",
      "Input (English): Everyone will be there.\n",
      "Predicted Translation (French): [start] tout le monde sera là [end]\n",
      "Actual Translation (French): [start] Tout le monde va être là. [end]\n",
      "----------\n",
      "Input (English): I really like it.\n",
      "Predicted Translation (French): [start] je laime vraiment [end]\n",
      "Actual Translation (French): [start] Je kiffe trop. [end]\n",
      "----------\n",
      "Input (English): Is it that bad?\n",
      "Predicted Translation (French): [start] estce si mauvais que cest [UNK] [end]\n",
      "Actual Translation (French): [start] Est-ce si mal ? [end]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Loop to generate and display translations for 10 random sentences from the test set.\n",
    "for _ in range(10):\n",
    "    # Randomly select an index from the test dataset.\n",
    "    random_index = random.randint(0, len(X_test) - 1)\n",
    "\n",
    "    # Retrieve the corresponding English sentence from the test set.\n",
    "    input_sentence = test_eng_texts[random_index]\n",
    "\n",
    "    # Retrieve the actual French translation from the test set.\n",
    "    actual_translation = test_fra_texts[random_index]\n",
    "\n",
    "    # Use the 'decode_sequence' function to translate the English sentence.\n",
    "    translated = decode_sequence(input_sentence)\n",
    "\n",
    "    # Print the original English sentence.\n",
    "    print(\"Input (English):\", input_sentence)\n",
    "\n",
    "    # Print the model's translation.\n",
    "    print(\"Predicted Translation (French):\", translated)\n",
    "\n",
    "    # Print the actual French translation for comparison.\n",
    "    print(\"Actual Translation (French):\", actual_translation)\n",
    "\n",
    "    # Print a separator for readability.\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hf6M3T-B_Xa3"
   },
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgIhs7jz_QQH"
   },
   "outputs": [],
   "source": [
    "# For attention model\n",
    "def translate(sentence_en):\n",
    "    translation = \"\"\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])  # encoder input\n",
    "        X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_fra.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTt2LkEz_iw_"
   },
   "outputs": [],
   "source": [
    "# Define a function to translate an English sentence into French using the attention model.\n",
    "def translate(sentence_en):\n",
    "    # Initialize an empty string for the translation.\n",
    "    translation = \"\"\n",
    "\n",
    "    # Iterate over the maximum possible length of the output sentence.\n",
    "    for word_idx in range(max_length):\n",
    "        # Prepare the encoder input as an array with the English sentence.\n",
    "        X = np.array([sentence_en])\n",
    "\n",
    "        # Prepare the decoder input as an array with the partial translation.\n",
    "        X_dec = np.array([\"startofseq \" + translation])\n",
    "\n",
    "        # Predict the probability distribution for the next word in the sequence.\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]\n",
    "\n",
    "        # Find the index of the word with the highest probability.\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "\n",
    "        # Retrieve the predicted word from the French vocabulary.\n",
    "        predicted_word = text_vec_layer_fra.get_vocabulary()[predicted_word_id]\n",
    "\n",
    "        # Break the loop if the 'endofseq' token is predicted.\n",
    "        if predicted_word == \"endofseq\":\n",
    "            break\n",
    "\n",
    "        # Add the predicted word to the ongoing translation.\n",
    "        translation += \" \" + predicted_word\n",
    "\n",
    "    # Return the completed translation, removing any leading or trailing whitespace.\n",
    "    return translation.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--_YoX5h_oW8"
   },
   "outputs": [],
   "source": [
    "# Extract English texts from each pair in the test dataset and store them in a list.\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "\n",
    "# Extract French texts (intended to be the translations of the English texts) from each pair in the test dataset and store them in a separate list.\n",
    "test_fra_texts = [pair[1] for pair in test_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZe6kA9t_rGO"
   },
   "outputs": [],
   "source": [
    "# Initialize empty lists to store the original English sentences and their actual French translations.\n",
    "reference_en_translation = []\n",
    "reference_fra_translation = []\n",
    "\n",
    "# Initialize empty lists to store the translations produced by the attention model and the transformer model.\n",
    "attention_model_test_results_fra = []\n",
    "transformer_model_test_results_fra = []\n",
    "\n",
    "# Loop to generate and store translations for 20 random sentences from the test set.\n",
    "for _ in range(20):\n",
    "    # Randomly select an index from the test dataset.\n",
    "    random_index = random.randint(0, len(X_test) - 1)\n",
    "\n",
    "    # Retrieve the corresponding English sentence from the test set.\n",
    "    input_sentence = test_eng_texts[random_index]\n",
    "\n",
    "    # Retrieve the actual French translation from the test set.\n",
    "    actual_translation = test_fra_texts[random_index]\n",
    "\n",
    "    # Use the 'decode_sequence' function from the transformer model to translate the English sentence.\n",
    "    transformer_translated = decode_sequence(input_sentence)\n",
    "\n",
    "    # Use the 'translate' function from the attention model to translate the English sentence.\n",
    "    attention_translated = translate(input_sentence)\n",
    "\n",
    "    # Store the original English sentence and its actual French translation.\n",
    "    reference_en_translation.append(input_sentence)\n",
    "    reference_fra_translation.append(actual_translation)\n",
    "\n",
    "    # Store the translations produced by the attention model and the transformer model.\n",
    "    attention_model_test_results_fra.append(attention_translated)\n",
    "    transformer_model_test_results_fra.append(transformer_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gw_PfzDLA13r"
   },
   "outputs": [],
   "source": [
    "# Compute the BLEU score for the attention model's translations.\n",
    "# This score is a measure of how similar the model's translations are to the reference translations.\n",
    "attention_model_BLEU = google_bleu_metric.compute(\n",
    "    predictions=attention_model_test_results_fra,  # The translations produced by the attention model.\n",
    "    references=reference_fra_translation,          # The actual/reference French translations.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOEK7bd3A3-9"
   },
   "outputs": [],
   "source": [
    "# Compute the BLEU score for the transformer model's translations.\n",
    "# The BLEU score is used to evaluate the quality of machine translation, with a higher score indicating better translation.\n",
    "transformer_model_BLEU = google_bleu_metric.compute(\n",
    "    predictions=transformer_model_test_results_fra,  # The list of translations made by the transformer model.\n",
    "    references=reference_fra_translation,            # The actual/reference French translations for comparison.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Isl5JeSmA13s",
    "outputId": "a3544bba-0f50-45d3-ec54-a78ef12390ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION MODEL ROUGE RESULTS:\n",
      "{'google_bleu': 0.03205128205128205}\n"
     ]
    }
   ],
   "source": [
    "# Print the BLEU score results for the attention model.\n",
    "print('ATTENTION MODEL BLEU RESULTS:')\n",
    "print(attention_model_BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Et_sXPNeBCcv",
    "outputId": "548e067c-1b03-47e4-bdec-8fb3e409ba0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION MODEL ROUGE RESULTS:\n",
      "{'google_bleu': 0.3560311284046693}\n"
     ]
    }
   ],
   "source": [
    "print('ATTENTION MODEL ROUGE RESULTS:')\n",
    "print(transformer_model_BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "3xe9UP2KBD2I",
    "outputId": "71649646-31ee-4a61-ad55-38c71f1e0047"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rouge results for the attention model\n",
    "attention_model_BLUE = {'google_bleu': 0.03205128205128205}\n",
    "\n",
    "# Rouge results for the transformer model\n",
    "transformer_model_BLUE = {'google_bleu': 0.3560311284046693}\n",
    "\n",
    "# Extract model names and corresponding BLEU scores\n",
    "models = ['Attention Model', 'Transformer Model']\n",
    "bleu_scores = [attention_model_BLUE['google_bleu'], transformer_model_BLUE['google_bleu']]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.bar(models, bleu_scores, color=['blue', 'green'])\n",
    "plt.ylabel('BLEU Score')\n",
    "plt.title('Google BLEU Score Comparison')\n",
    "plt.ylim(0, 1)  # Set the y-axis limit to better visualize the differences\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17cb74e7ccde4176b37c70db7f2827ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a9daccda74b54758875bafbf11212c81",
       "IPY_MODEL_d8fb0e935f09496bac25aa3fddf16be4",
       "IPY_MODEL_c25c76584bd740008e6dee60a3a52821"
      ],
      "layout": "IPY_MODEL_2644859a14274703a9ef7a4ca999d3bc"
     }
    },
    "2644859a14274703a9ef7a4ca999d3bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40ee584d517d4c2a8ef822fe7d7ac6f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fecd2e82e6b418e9e6e3ea5ff9617e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "640bb6bd59fb402cb87bc910bdfea9be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "752bb9388daf4dcc8a335fd1bf6d8d77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1e117055642430fb7fffc585be99960",
      "max": 3344,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f1bdc243687476baf0d58ec5e111a99",
      "value": 3344
     }
    },
    "7f1bdc243687476baf0d58ec5e111a99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "866363d3aafe484b90becd99bf9176e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcbaa7ce6a094e11b74cc4d673b3e786",
      "placeholder": "​",
      "style": "IPY_MODEL_40ee584d517d4c2a8ef822fe7d7ac6f0",
      "value": "Downloading extra modules: 100%"
     }
    },
    "9a7a1d53e84947c7aa059f1e9eaa7747": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cf5e2fa5a8c440eb4ef7aa2540280d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b940754320304c1b905c80701a536612",
      "placeholder": "​",
      "style": "IPY_MODEL_b3cd22d8466f401bbf44c15682e84822",
      "value": " 3.34k/3.34k [00:00&lt;00:00, 185kB/s]"
     }
    },
    "a142794168b9416c9aaa80fb49f668b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1e117055642430fb7fffc585be99960": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9daccda74b54758875bafbf11212c81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a7a1d53e84947c7aa059f1e9eaa7747",
      "placeholder": "​",
      "style": "IPY_MODEL_4fecd2e82e6b418e9e6e3ea5ff9617e2",
      "value": "Downloading builder script: 100%"
     }
    },
    "b3cd22d8466f401bbf44c15682e84822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b940754320304c1b905c80701a536612": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c25c76584bd740008e6dee60a3a52821": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da8f8fe4ef4b4bbb87acbcb94ae21f03",
      "placeholder": "​",
      "style": "IPY_MODEL_640bb6bd59fb402cb87bc910bdfea9be",
      "value": " 8.64k/8.64k [00:00&lt;00:00, 194kB/s]"
     }
    },
    "d8fb0e935f09496bac25aa3fddf16be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3a0efe8426c4945a157c4f39b46cdeb",
      "max": 8645,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a142794168b9416c9aaa80fb49f668b9",
      "value": 8645
     }
    },
    "d917fcf597d1461d8333e8637f4fc6c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_866363d3aafe484b90becd99bf9176e1",
       "IPY_MODEL_752bb9388daf4dcc8a335fd1bf6d8d77",
       "IPY_MODEL_9cf5e2fa5a8c440eb4ef7aa2540280d7"
      ],
      "layout": "IPY_MODEL_fa1de26e47644f5e99f4709e8dd9fe1b"
     }
    },
    "da8f8fe4ef4b4bbb87acbcb94ae21f03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcbaa7ce6a094e11b74cc4d673b3e786": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3a0efe8426c4945a157c4f39b46cdeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa1de26e47644f5e99f4709e8dd9fe1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
